{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from skimage.feature import hog, local_binary_pattern, graycomatrix, graycoprops\n",
    "from skimage import exposure, color\n",
    "from tensorflow.keras.applications import VGG16  # Changed from ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.svm import SVC  # Added new classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # Added new classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed  # For parallel processing\n",
    "import time  # For timing operations\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Load and prepare dataset\n",
    "def load_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    y_train, y_test = y_train.ravel(), y_test.ravel()\n",
    "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "    return (x_train, y_train), (x_test, y_test), class_names\n",
    "\n",
    "(x_train, y_train), (x_test, y_test), class_names = load_cifar10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Enhanced Visualization\n",
    "def plot_sample_images(images, labels, class_names, title=\"Sample Images\"):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"{class_names[labels[i]]} ({labels[i]})\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(x_train, y_train, class_names, \"Original Training Images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Improved Preprocessing\n",
    "def preprocess_images(images, target_size=(64, 64), convert_to='gray'):\n",
    "    \"\"\"\n",
    "    Enhanced preprocessing with multiple options\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for img in images:\n",
    "        if convert_to == 'gray':\n",
    "            img_proc = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        elif convert_to == 'hsv':\n",
    "            img_proc = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif convert_to == 'lab':\n",
    "            img_proc = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "        else:\n",
    "            img_proc = img.copy()\n",
    "            \n",
    "        img_proc = cv2.resize(img_proc, target_size)\n",
    "        processed.append(img_proc)\n",
    "    \n",
    "    return np.array(processed) / 255.0  # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process images in different color spaces\n",
    "x_train_gray = preprocess_images(x_train, convert_to='gray')\n",
    "x_test_gray = preprocess_images(x_test, convert_to='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Feature Extraction Functions\n",
    "def extract_hog_features(images, visualize=False):\n",
    "    \"\"\"\n",
    "    Enhanced HOG feature extraction with options\n",
    "    \"\"\"\n",
    "    if visualize:\n",
    "        features, hog_images = zip(*[hog(img, pixels_per_cell=(16, 16), \n",
    "                                      cells_per_block=(2, 2), \n",
    "                                      visualize=True, channel_axis=None) \n",
    "                                   for img in images])\n",
    "        return np.array(features), np.array(hog_images)\n",
    "    else:\n",
    "        features = [hog(img, pixels_per_cell=(16, 16), \n",
    "                   cells_per_block=(2, 2), \n",
    "                   channel_axis=None) \n",
    "                   for img in images]\n",
    "        return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(images):\n",
    "    features = Parallel(n_jobs=-1)(\n",
    "        delayed(lambda img: \n",
    "            np.histogram(\n",
    "                local_binary_pattern((img * 255).astype(np.uint8),  # Convert to uint8\n",
    "                P=16, R=2, method='uniform'),\n",
    "                bins=np.arange(0, 16 + 3)\n",
    "            )[0]\n",
    "        )(img) for img in images\n",
    "    )\n",
    "    return np.array(features)\n",
    "\n",
    "def extract_lbp_features(images, P=16, R=2, method='uniform'):\n",
    "    \"\"\"\n",
    "    Enhanced LBP with more parameters\n",
    "    \"\"\"\n",
    "    features = Parallel(n_jobs=-1)(\n",
    "        delayed(lambda img: \n",
    "            np.histogram(\n",
    "                local_binary_pattern(img, P=P, R=R, method=method),\n",
    "                bins=np.arange(0, P + 3),\n",
    "                range=(0, P + 2)\n",
    "            )[0].astype(\"float\") / 255.0\n",
    "        )(img) for img in images\n",
    "    )\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_glcm_features(images, distances=[5], angles=[0], properties=['contrast', 'homogeneity']):\n",
    "    \"\"\"\n",
    "    New GLCM feature extraction\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for img in (images * 255).astype(np.uint8):\n",
    "        glcm = graycomatrix(img, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "        feature = np.hstack([graycoprops(glcm, prop).ravel() for prop in properties])\n",
    "        features.append(feature)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sift_features(images, max_features=50):\n",
    "    \"\"\"\n",
    "    New SIFT feature extraction\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    features = []\n",
    "    for img in (images * 255).astype(np.uint8):\n",
    "        _, desc = sift.detectAndCompute(img, None)\n",
    "        if desc is not None:\n",
    "            # Take first 'max_features' or pad if needed\n",
    "            desc = desc[:max_features].flatten()\n",
    "            if len(desc) < max_features * 128:\n",
    "                desc = np.pad(desc, (0, max_features * 128 - len(desc)))\n",
    "        else:\n",
    "            desc = np.zeros(max_features * 128)\n",
    "        features.append(desc)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# CNN Feature Extraction (using VGG16 instead of ResNet)\n",
    "def extract_cnn_features(images):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.output)\n",
    "    \n",
    "    # Preprocess for VGG\n",
    "    processed = np.array([cv2.resize(img, (64, 64)) for img in images])\n",
    "    processed = preprocess_input(processed)\n",
    "    \n",
    "    features = model.predict(processed, batch_size=32)\n",
    "    return features.reshape(features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Extract all features (with timing)\n",
    "feature_sets = {}\n",
    "\n",
    "print(\"Extracting HOG features...\")\n",
    "start = time.time()\n",
    "x_train_hog, hog_images = extract_hog_features(x_train_gray, visualize=True)\n",
    "x_test_hog = extract_hog_features(x_test_gray)\n",
    "feature_sets['HOG'] = (x_train_hog, x_test_hog)\n",
    "print(f\"HOG features extracted in {time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtracting LBP features...\")\n",
    "start = time.time()\n",
    "x_train_lbp = extract_lbp_features(x_train_gray)\n",
    "x_test_lbp = extract_lbp_features(x_test_gray)\n",
    "feature_sets['LBP'] = (x_train_lbp, x_test_lbp)\n",
    "print(f\"LBP features extracted in {time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtracting GLCM features...\")\n",
    "start = time.time()\n",
    "x_train_glcm = extract_glcm_features(x_train_gray)\n",
    "x_test_glcm = extract_glcm_features(x_test_gray)\n",
    "feature_sets['GLCM'] = (x_train_glcm, x_test_glcm)\n",
    "print(f\"GLCM features extracted in {time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtracting SIFT features...\")\n",
    "start = time.time()\n",
    "x_train_sift = extract_sift_features(x_train_gray)\n",
    "x_test_sift = extract_sift_features(x_test_gray)\n",
    "feature_sets['SIFT'] = (x_train_sift, x_test_sift)\n",
    "print(f\"SIFT features extracted in {time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nExtracting CNN features...\")\n",
    "start = time.time()\n",
    "x_train_cnn = extract_cnn_features(x_train)\n",
    "x_test_cnn = extract_cnn_features(x_test)\n",
    "feature_sets['CNN'] = (x_train_cnn, x_test_cnn)\n",
    "print(f\"CNN features extracted in {time.time()-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(original, features, title):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original Image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Feature Representation\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if len(features.shape) == 2:  # 2D features (HOG image, CNN activations)\n",
    "        plt.imshow(features, aspect='auto', cmap='viridis')\n",
    "    elif len(features.shape) == 1:  # 1D features (LBP/GLCM histograms)\n",
    "        plt.bar(range(len(features)), features)\n",
    "        plt.xlabel(\"Feature Bins\")\n",
    "    else:  # Raw 2D features (SIFT keypoints)\n",
    "        plt.imshow(features, cmap='gray')\n",
    "    plt.title(\"Feature Representation\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Feature Distribution\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist(features.flatten(), bins=50)\n",
    "    plt.title(\"Feature Distribution\")\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For HOG (2D features)\n",
    "visualize_features(x_train_gray[0], hog_images[0], \"HOG Features\")\n",
    "\n",
    "# For LBP (1D histogram)\n",
    "visualize_features(x_train_gray[0], x_train_lbp[0], \"LBP Features\")\n",
    "\n",
    "# For GLCM (1D vector)\n",
    "visualize_features(x_train_gray[0], x_train_glcm[0], \"GLCM Features\")\n",
    "\n",
    "# For SIFT (2D keypoints - if applicable)\n",
    "visualize_features(x_train_gray[0], x_train_sift[0].reshape(64,64), \"SIFT Features\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Model Training and Evaluation\n",
    "def train_and_evaluate(feature_name, x_train, x_test, model_type='svm'):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training with {feature_name} features\")\n",
    "    \n",
    "    if model_type == 'svm':\n",
    "        model = SVC(kernel='rbf', C=10, gamma='scale')\n",
    "    elif model_type == 'gbm':\n",
    "        model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
    "    else:\n",
    "        model = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    start = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    train_time = time.time() - start\n",
    "    \n",
    "    start = time.time()\n",
    "    y_pred = model.predict(x_test)\n",
    "    pred_time = time.time() - start\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nResults for {feature_name} with {model.__class__.__name__}:\")\n",
    "    print(f\"Training time: {train_time:.2f}s\")\n",
    "    print(f\"Prediction time: {pred_time:.2f}s\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "     # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrBr', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix: {feature_name} Features\\n{model.__class__.__name__}')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, train_time, pred_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate all feature sets\n",
    "results = []\n",
    "for feature_name, (x_train_feat, x_test_feat) in feature_sets.items():\n",
    "    # Use SVM for high-dim features, GBM for others\n",
    "    model_type = 'svm' if feature_name in ['HOG', 'CNN', 'SIFT'] else 'gbm'\n",
    "    acc, train_time, pred_time = train_and_evaluate(\n",
    "        feature_name, x_train_feat, x_test_feat, model_type\n",
    "    )\n",
    "    results.append({\n",
    "        'Feature': feature_name,\n",
    "        'Model': 'SVM' if model_type == 'svm' else 'GBM',\n",
    "        'Accuracy': acc,\n",
    "        'Train Time': train_time,\n",
    "        'Prediction Time': pred_time\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these imports at the TOP of your notebook/script\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your existing comparative analysis code\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nComparative Results:\")\n",
    "print(results_df)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Feature', y='Accuracy', data=results_df, palette='viridis')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Feature', y='Train Time', data=results_df, palette='rocket')\n",
    "plt.title('Training Time Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "# Feature Importance Analysis (for tree-based models)\n",
    "def plot_feature_importance(model, feature_name):\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        importances = model.feature_importances_\n",
    "        plt.bar(range(len(importances)), importances)\n",
    "        plt.title(f'Feature Importance - {feature_name}')\n",
    "        plt.xlabel('Feature Index')\n",
    "        plt.ylabel('Importance')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for one of the models\n",
    "plot_feature_importance(GradientBoostingClassifier().fit(x_train_lbp, y_train), 'LBP')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
